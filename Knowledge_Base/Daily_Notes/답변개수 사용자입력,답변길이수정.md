**요청하신 두 가지 기능을 반영한 개선 코드**입니다.  
중복 결과 제거 및 검색 결과 길이 조정을 구현했습니다.

---

### **개선된 전체 코드**
```python
import os
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# 설정 변수
EMBEDDING_MODEL = "text-embedding-ada-002"
PERSIST_DIR = "./chroma_db"
KNOWLEDGE_DIR = "./Knowledge_Base"

# (1) 모델/DB 캐싱 로직
if not os.path.exists(PERSIST_DIR):
    print("⏳ 처음 실행: 문서 로딩 및 벡터 DB 생성 중...")
    loader = DirectoryLoader(
        KNOWLEDGE_DIR,
        glob='**/*.md',
        loader_cls=TextLoader,
        loader_kwargs={'encoding': 'utf-8'},
        recursive=True,
        show_progress=True
    )
    docs = loader.load()
    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)
    db = Chroma.from_documents(docs, embeddings, persist_directory=PERSIST_DIR)
    db.persist()
    print("✅ 벡터 DB 생성 완료")
else:
    print("🚀 기존 벡터 DB 로딩 중...")
    embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)
    db = Chroma(persist_directory=PERSIST_DIR, embedding_function=embeddings)
    print("✅ DB 로딩 완료")

# (2) 개선된 검색 함수
def search(query: str, top_n: int = 3, min_length: int = 500):
    results = db.similarity_search_with_score(query, k=top_n*2)  # 후보군 확장
    
    seen = set()  # 중복 검사용
    filtered = []
    
    for doc, score in results:
        doc_id = doc.metadata.get('source', 'unknown')
        if doc_id not in seen:
            seen.add(doc_id)
            # 길이 조정 (min_length 적용)
            content = doc.page_content
            if len(content) < min_length:
                content += "..."  # 짧은 경우 표시
            else:
                content = content[:min_length] + "..."
            filtered.append((doc, score, content))
            if len(filtered) >= top_n:
                break
    
    print(f"\n🔍 '{query}' 검색 결과 (상위 {len(filtered)}개):")
    for i, (doc, score, content) in enumerate(filtered, 1):
        print(f"\n[{i}] (유사도: {score:.2f})")
        print(f"출처: {doc.metadata['source']}")
        print(f"내용: {content}")

# (3) 사용자 입력 처리
if __name__ == "__main__":
    while True:
        query = input("\n❓ 질문을 입력하세요 (종료: q): ")
        if query.lower() == 'q':
            break
        
        # 사용자 정의 옵션
        try:
            top_n = int(input("📌 표시할 결과 개수 (기본 3): ") or 3)
            min_length = int(input("📌 최소 내용 길이 (기본 500자): ") or 500)
        except ValueError:
            print("⚠️ 숫자만 입력 가능합니다. 기본값으로 진행합니다.")
            top_n, min_length = 3, 500
        
        search(query, top_n=top_n, min_length=min_length)
```

---

### **주요 개선 사항**
#### **1. 사용자 정의 검색 옵션**
- **결과 개수**: `top_n` 매개변수 추가 (기본 3)
- **내용 길이**: `min_length` 매개변수 추가 (기본 500자)

#### **2. 중복 결과 필터링**
- `seen` 셋을 사용해 동일 문서 중복 제거
- 유사도 점수 순으로 정렬 유지

#### **3. 스마트 길이 조절**
- 짧은 문서: `...` 추가
- 긴 문서: 지정한 길이만큼 자르기

---

### **실행 예시**
```bash
❓ 질문을 입력하세요 (종료: q): LLM 배치 크기
📌 표시할 결과 개수 (기본 3): 5
📌 최소 내용 길이 (기본 500자): 1000

🔍 'LLM 배치 크기' 검색 결과 (상위 5개):

[1] (유사도: 0.92)
출처: LLM_Optimization.md
내용: LLM 학습 시 배치 크기(batch size)는 32 권장...
(1000자까지 표시)

[2] (유사도: 0.88)
출처: Training_Tips.md
내용: 배치 크기가 너무 크면 메모리 부족...
(1000자까지 표시)

[3] (유사도: 0.85)
출처: Performance_Guide.md
내용: GPU 메모리에 따라 배치 크기 조절 필요...
(1000자까지 표시)

[4] (유사도: 0.81)
출처: Hardware_Requirements.md
내용: RTX 4090 기준 최대 배치 크기...
(1000자까지 표시)

[5] (유사도: 0.77)
출처: Troubleshooting.md
내용: 배치 크기 1024로 설정 시 발생하는 문제...
(1000자까지 표시)
```

---

### **추가 개선 가능 영역**
1. **동적 길이 조절**:
   ```python
   # 문서 전체 길이의 70%만 표시
   content_length = int(len(doc.page_content) * 0.7)
   ```
2. **형식 강조**:
   ```python
   from rich.console import Console
   console = Console()
   console.print(f"[bold]{content}[/bold]")
   ```
3. **JSON 출력**:
   ```python
   import json
   print(json.dumps(results, indent=2, ensure_ascii=False))
   ```

이제 **사용자 맞춤형 검색**과 **고품질 결과**를 얻을 수 있습니다! 😊